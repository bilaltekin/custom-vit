{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ff5ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a30be0e",
   "metadata": {},
   "source": [
    "https://github.com/lucidrains/vit-pytorch?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b853c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Custom Dataset ---\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            cls_path = os.path.join(root_dir, cls)\n",
    "            for img_name in os.listdir(cls_path):\n",
    "                self.image_paths.append(os.path.join(cls_path, img_name))\n",
    "                self.labels.append(self.class_to_idx[cls])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d281e1af-41a8-4473-b213-0d7f18b552ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout),\n",
    "                FeedForward(dim, mlp_dim, dropout = dropout)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94af16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses, preds, targets = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    prec, recall, f1, _ = precision_recall_fscore_support(targets, preds, average='macro', zero_division=0)\n",
    "    return np.mean(losses), acc, prec, recall, f1, preds, targets\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler,train_loader, val_loader, test_loader, device,\n",
    "                num_epochs, save_policy='min', base_output_dir='logs', class_names=None):\n",
    "\n",
    "    # Create timestamped main directory\n",
    "    now = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    #run_dir = os.path.join(base_output_dir, f'run_{now}')\n",
    "    run_dir=base_output_dir\n",
    "    model_dir = os.path.join(run_dir, 'models')\n",
    "    metric_dir = os.path.join(run_dir, 'metrics')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(metric_dir, exist_ok=True)\n",
    "\n",
    "    best_val_score = float('-inf')\n",
    "    worst_val_score = float('inf')\n",
    "    start_training_time = time.time()\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "  \n",
    "    # Prepare header\n",
    "    train_log_path = os.path.join(metric_dir, 'train_log.txt')\n",
    "    val_log_path = os.path.join(metric_dir, 'val_log.txt')\n",
    "\n",
    "    with open(train_log_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Epoch', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Time'])\n",
    "\n",
    "    with open(val_log_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Epoch', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Time'])\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"Starting time:\", now.replace(\"_\", \" \"))\n",
    "\n",
    "    \n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_losses, train_preds, train_targets = [], [], []\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "           \n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Train metrics\n",
    "        train_loss = np.mean(train_losses)\n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_prec, train_rec, train_f1, _ = precision_recall_fscore_support(train_targets, train_preds, average='macro', zero_division=0)\n",
    "\n",
    "        # Validation metrics\n",
    "        val_loss, val_acc, val_prec, val_rec, val_f1, _, _ = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "        print(f\"Train | Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_prec:.4f} | Rec: {train_rec:.4f} | F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   | Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | Prec: {val_prec:.4f} | Rec: {val_rec:.4f} | F1: {val_f1:.4f}\")\n",
    "        print(f\"Epoch Time: {str(timedelta(seconds=epoch_time))} sec\\n\")\n",
    "\n",
    "\n",
    "       # Append metrics in CSV-like format to .txt files (rounded to 4 decimal places)\n",
    "        with open(train_log_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch,\n",
    "                round(train_loss, 4),\n",
    "                round(train_acc, 4),\n",
    "                round(train_prec, 4),\n",
    "                round(train_rec, 4),\n",
    "                round(train_f1, 4),\n",
    "                round(epoch_time, 4)\n",
    "            ])\n",
    "\n",
    "        with open(val_log_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch,\n",
    "                round(val_loss, 4),\n",
    "                round(val_acc, 4),\n",
    "                round(val_prec, 4),\n",
    "                round(val_rec, 4),\n",
    "                round(val_f1, 4),\n",
    "                round(epoch_time, 4)\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Save model based on policy\n",
    "        epoch_model_path = os.path.join(model_dir, f'epoch_{epoch:04d}.pt')\n",
    "\n",
    "        if save_policy == 'max':\n",
    "            if val_acc > best_val_score:\n",
    "                best_val_score = val_acc\n",
    "                torch.save(model.state_dict(), os.path.join(model_dir, 'best_model.pt'))\n",
    "                torch.save(model.state_dict(), epoch_model_path)\n",
    "\n",
    "        elif save_policy == 'min':\n",
    "            if val_loss < worst_val_score:\n",
    "                worst_val_score = val_loss\n",
    "                torch.save(model.state_dict(), os.path.join(model_dir, 'best_model.pt'))\n",
    "                torch.save(model.state_dict(), epoch_model_path)\n",
    "\n",
    "        elif save_policy == 'all':\n",
    "            torch.save(model.state_dict(), epoch_model_path)\n",
    "\n",
    "        elif save_policy == 'last':\n",
    "            torch.save(model.state_dict(), epoch_model_path)\n",
    "            torch.save(model.state_dict(), os.path.join(model_dir, 'best_model.pt'))\n",
    "\n",
    "    total_time = time.time() - start_training_time\n",
    "    print(\"Finish time:\", datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\"))\n",
    "    print(f\"Total training time: {str(timedelta(seconds=total_time))} seconds\")\n",
    "\n",
    "\n",
    "    print(\"\\nðŸŽ¯ Final Evaluation on Test Set:\")\n",
    "    test_loss, test_acc, test_prec, test_rec, test_f1, test_preds, test_targets = evaluate_model(model, test_loader, criterion, device)\n",
    "    print(f\"Test | Loss: {test_loss:.4f} | Acc: {test_acc:.4f} | Prec: {test_prec:.4f} | Rec: {test_rec:.4f} | F1: {test_f1:.4f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(test_targets, test_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    xticks = yticks = class_names if class_names else range(len(cm))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=xticks, yticklabels=yticks)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(metric_dir, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Load best model and evaluate again\n",
    "    model.load_state_dict(torch.load(os.path.join(model_dir, 'best_model.pt')))\n",
    "    \n",
    "    test_loss, test_acc, test_prec, test_rec, test_f1, test_preds, test_targets = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Best Model | Loss: {test_loss:.4f} | Acc: {test_acc:.4f} | Prec: {test_prec:.4f} | Rec: {test_rec:.4f} | F1: {test_f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4a9a7-14f9-4b4c-8aaa-4016230bc91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21976291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef07d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Settings ---\n",
    "\n",
    "image_dir = 'DataSet/top-agriculture-crop-disease'          # Folder where images are stored\n",
    "image_size = 32\n",
    "batch_size = 32\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "num_workers = 4\n",
    "save_dir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "587a3a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 3 classes: ['Potato___Early_Blight', 'Potato___Healthy', 'Potato___Late_Blight']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Transforms ---\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# --- Load full dataset ---\n",
    "full_dataset = CustomDataset( image_dir)\n",
    "num_samples = len(full_dataset)\n",
    "num_val = int(num_samples * val_ratio)\n",
    "num_test = int(num_samples * test_ratio)\n",
    "num_train = num_samples - num_val - num_test\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42  # You can change this to any integer\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# --- Split dataset ---\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [num_train, num_val, num_test],generator=generator)\n",
    "\n",
    "# Assign transforms after split\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_test_transform\n",
    "test_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "# --- DataLoaders ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# --- Class Info ---\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Loaded dataset with {num_classes} classes: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b1188",
   "metadata": {},
   "source": [
    "# normal train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af08c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Saving all folds under: logs/run_2025-07-20_13-26-54\n",
      "Starting time: 2025-07-20 13-26-54\n",
      "Epoch [1/2]\n",
      "Train | Loss: 0.6999 | Acc: 0.6896 | Prec: 0.6921 | Rec: 0.6894 | F1: 0.6904\n",
      "Val   | Loss: 0.3632 | Acc: 0.8725 | Prec: 0.8712 | Rec: 0.8734 | F1: 0.8720\n",
      "Epoch Time: 0:00:09.113515 sec\n",
      "\n",
      "Epoch [2/2]\n",
      "Train | Loss: 0.3754 | Acc: 0.8528 | Prec: 0.8518 | Rec: 0.8523 | F1: 0.8519\n",
      "Val   | Loss: 0.2605 | Acc: 0.8954 | Prec: 0.8943 | Rec: 0.8967 | F1: 0.8949\n",
      "Epoch Time: 0:00:09.098557 sec\n",
      "\n",
      "Finish time: 20-07-2025 13:27:14\n",
      "Total training time: 0:00:20.013708 seconds\n",
      "\n",
      "ðŸŽ¯ Final Evaluation on Test Set:\n",
      "Test | Loss: 0.2605 | Acc: 0.8954 | Prec: 0.8943 | Rec: 0.8967 | F1: 0.8949\n",
      "Best Model | Loss: 0.2605 | Acc: 0.8954 | Prec: 0.8943 | Rec: 0.8967 | F1: 0.8949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ViT(\n",
    "    image_size = 256,\n",
    "    patch_size = 16,\n",
    "    num_classes = len(class_names),\n",
    "    dim = 192,\n",
    "    depth = 9,\n",
    "    heads = 12,\n",
    "    mlp_dim = 384,\n",
    "    dropout = 0,\n",
    "    emb_dropout = 0\n",
    ")\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                                                    optimizer,T_max=num_epochs,eta_min=0)\n",
    "\n",
    "# === Tarihli ana klasÃ¶r oluÅŸtur ===\n",
    "run_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "run_dir = os.path.join(save_dir, f'run_{run_time}')\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "print(f\"ðŸ“ Saving all folds under: {run_dir}\")\n",
    "\n",
    "\n",
    "train_model(model, criterion,  optimizer, scheduler,  train_loader, val_loader, val_loader, device,\n",
    "                num_epochs=num_epochs, save_policy=save_policy,\n",
    "                base_output_dir=fold_save_dir,class_names=class_names)\n",
    "\n",
    "\n",
    "\n",
    "# Final test evaluation\n",
    "test_loss, test_acc, test_prec, test_rec, test_f1, _, _ = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "\n",
    "with open(os.path.join(run_dir, 'test_metrics.txt'), 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Loss', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "    writer.writerow([\n",
    "        round(test_loss, 4),\n",
    "        round(test_acc, 4),\n",
    "        round(test_prec, 4),\n",
    "        round(test_rec, 4),\n",
    "        round(test_f1, 4)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382c7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c201f75d",
   "metadata": {},
   "source": [
    "# kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37c5f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Saving all folds under: logs/run_2025-07-20_13-20-42\n",
      "Using device: cuda\n",
      "\n",
      "ðŸŒ€ Fold 1/5\n",
      "cuda\n",
      "Starting time: 2025-07-20 13-22-15\n",
      "Epoch [1/2]\n",
      "Train | Loss: 0.7652 | Acc: 0.6437 | Prec: 0.6471 | Rec: 0.6447 | F1: 0.6452\n",
      "Val   | Loss: 0.4892 | Acc: 0.7862 | Prec: 0.7874 | Rec: 0.7879 | F1: 0.7855\n",
      "Epoch Time: 0:00:17.838474 sec\n",
      "\n",
      "Epoch [2/2]\n",
      "Train | Loss: 0.2914 | Acc: 0.8957 | Prec: 0.8967 | Rec: 0.8954 | F1: 0.8957\n",
      "Val   | Loss: 0.1892 | Acc: 0.9312 | Prec: 0.9322 | Rec: 0.9305 | F1: 0.9309\n",
      "Epoch Time: 0:00:22.114286 sec\n",
      "\n",
      "Finish time: 20-07-2025 13:22:56\n",
      "Total training time: 0:00:41.093918 seconds\n",
      "\n",
      "ðŸŽ¯ Final Evaluation on Test Set:\n",
      "Test | Loss: 0.1892 | Acc: 0.9312 | Prec: 0.9322 | Rec: 0.9305 | F1: 0.9309\n",
      "Best Model | Loss: 0.1892 | Acc: 0.9312 | Prec: 0.9322 | Rec: 0.9305 | F1: 0.9309\n",
      "\n",
      "ðŸŒ€ Fold 2/5\n",
      "cuda\n",
      "Starting time: 2025-07-20 13-23-05\n",
      "Epoch [1/2]\n",
      "Train | Loss: 0.7241 | Acc: 0.6931 | Prec: 0.6936 | Rec: 0.6940 | F1: 0.6938\n",
      "Val   | Loss: 0.4326 | Acc: 0.8351 | Prec: 0.8401 | Rec: 0.8347 | F1: 0.8359\n",
      "Epoch Time: 0:00:22.501004 sec\n",
      "\n",
      "Epoch [2/2]\n",
      "Train | Loss: 0.2972 | Acc: 0.8921 | Prec: 0.8940 | Rec: 0.8914 | F1: 0.8919\n",
      "Val   | Loss: 0.2888 | Acc: 0.8877 | Prec: 0.8925 | Rec: 0.8892 | F1: 0.8882\n",
      "Epoch Time: 0:00:22.652251 sec\n",
      "\n",
      "Finish time: 20-07-2025 13:23:51\n",
      "Total training time: 0:00:46.342889 seconds\n",
      "\n",
      "ðŸŽ¯ Final Evaluation on Test Set:\n",
      "Test | Loss: 0.2888 | Acc: 0.8877 | Prec: 0.8925 | Rec: 0.8892 | F1: 0.8882\n",
      "Best Model | Loss: 0.2888 | Acc: 0.8877 | Prec: 0.8925 | Rec: 0.8892 | F1: 0.8882\n",
      "\n",
      "ðŸŒ€ Fold 3/5\n",
      "cuda\n",
      "Starting time: 2025-07-20 13-24-00\n",
      "Epoch [1/2]\n",
      "Train | Loss: 0.7480 | Acc: 0.6673 | Prec: 0.6730 | Rec: 0.6660 | F1: 0.6675\n",
      "Val   | Loss: 0.3758 | Acc: 0.8714 | Prec: 0.8811 | Rec: 0.8731 | F1: 0.8739\n",
      "Epoch Time: 0:00:22.908086 sec\n",
      "\n",
      "Epoch [2/2]\n",
      "Train | Loss: 0.2512 | Acc: 0.9184 | Prec: 0.9191 | Rec: 0.9179 | F1: 0.9181\n",
      "Val   | Loss: 0.1823 | Acc: 0.9221 | Prec: 0.9277 | Rec: 0.9204 | F1: 0.9217\n",
      "Epoch Time: 0:00:23.020687 sec\n",
      "\n",
      "Finish time: 20-07-2025 13:24:47\n",
      "Total training time: 0:00:47.356699 seconds\n",
      "\n",
      "ðŸŽ¯ Final Evaluation on Test Set:\n",
      "Test | Loss: 0.1823 | Acc: 0.9221 | Prec: 0.9277 | Rec: 0.9204 | F1: 0.9217\n",
      "Best Model | Loss: 0.1823 | Acc: 0.9221 | Prec: 0.9277 | Rec: 0.9204 | F1: 0.9217\n",
      "\n",
      "ðŸŒ€ Fold 4/5\n",
      "cuda\n",
      "Starting time: 2025-07-20 13-24-55\n",
      "Epoch [1/2]\n",
      "Train | Loss: 0.7591 | Acc: 0.6652 | Prec: 0.6686 | Rec: 0.6649 | F1: 0.6660\n",
      "Val   | Loss: 0.4076 | Acc: 0.8730 | Prec: 0.8981 | Rec: 0.8705 | F1: 0.8725\n",
      "Epoch Time: 0:00:23.345478 sec\n",
      "\n",
      "Epoch [2/2]\n",
      "Train | Loss: 0.2826 | Acc: 0.9076 | Prec: 0.9089 | Rec: 0.9071 | F1: 0.9074\n",
      "Val   | Loss: 0.1435 | Acc: 0.9456 | Prec: 0.9453 | Rec: 0.9456 | F1: 0.9454\n",
      "Epoch Time: 0:00:24.292147 sec\n",
      "\n",
      "Finish time: 20-07-2025 13:25:45\n",
      "Total training time: 0:00:49.469701 seconds\n",
      "\n",
      "ðŸŽ¯ Final Evaluation on Test Set:\n",
      "Test | Loss: 0.1435 | Acc: 0.9456 | Prec: 0.9453 | Rec: 0.9456 | F1: 0.9454\n",
      "Best Model | Loss: 0.1435 | Acc: 0.9456 | Prec: 0.9453 | Rec: 0.9456 | F1: 0.9454\n",
      "\n",
      "ðŸŒ€ Fold 5/5\n",
      "cuda\n",
      "Starting time: 2025-07-20 13-25-55\n",
      "Epoch [1/2]\n",
      "Train | Loss: 0.8215 | Acc: 0.6266 | Prec: 0.6325 | Rec: 0.6261 | F1: 0.6282\n",
      "Val   | Loss: 0.5559 | Acc: 0.7387 | Prec: 0.7655 | Rec: 0.7420 | F1: 0.7377\n",
      "Epoch Time: 0:00:23.710150 sec\n",
      "\n",
      "Epoch [2/2]\n",
      "Train | Loss: 0.3260 | Acc: 0.8849 | Prec: 0.8852 | Rec: 0.8848 | F1: 0.8844\n",
      "Val   | Loss: 0.3719 | Acc: 0.8512 | Prec: 0.8755 | Rec: 0.8483 | F1: 0.8472\n",
      "Epoch Time: 0:00:23.894773 sec\n",
      "\n",
      "Finish time: 20-07-2025 13:26:44\n",
      "Total training time: 0:00:49.375130 seconds\n",
      "\n",
      "ðŸŽ¯ Final Evaluation on Test Set:\n",
      "Test | Loss: 0.3719 | Acc: 0.8512 | Prec: 0.8755 | Rec: 0.8483 | F1: 0.8472\n",
      "Best Model | Loss: 0.3719 | Acc: 0.8512 | Prec: 0.8755 | Rec: 0.8483 | F1: 0.8472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "save_dir=\"logs\"\n",
    "\n",
    "# === Tarihli ana klasÃ¶r oluÅŸtur ===\n",
    "run_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "run_dir = os.path.join(save_dir, f'run_{run_time}')\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "print(f\"ðŸ“ Saving all folds under: {run_dir}\")\n",
    "\n",
    "# === Parameters ===\n",
    "k_folds = 5\n",
    "image_dir = 'DataSet/top-agriculture-crop-disease'\n",
    "image_size = 256\n",
    "batch_size = 64\n",
    "num_epochs = 2\n",
    "save_policy = 'last'\n",
    "save_dir = 'logs'\n",
    "test_ratio = 0.1\n",
    "num_workers = 4\n",
    "seed = 42\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# === Transforms ===\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# === Load full dataset ===\n",
    "full_dataset = CustomDataset(image_dir)\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "\n",
    "# === Step 1: Split off test set ===\n",
    "total_size = len(full_dataset)\n",
    "test_size = int(total_size * test_ratio)\n",
    "trainval_size = total_size - test_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "trainval_dataset, test_dataset = random_split(full_dataset, [trainval_size, test_size], generator=generator)\n",
    "# Transforms uygulanÄ±r\n",
    "trainval_dataset.dataset.transform = train_transform\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# StratifiedKFold iÃ§in: trainval_dataset iÃ§indeki sÄ±ralamaya gÃ¶re alÄ±nÄ±r\n",
    "X = list(range(len(trainval_dataset)))\n",
    "y = [label for _, label in trainval_dataset]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "all_fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nðŸŒ€ Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    train_subset = Subset(trainval_dataset, train_idx)\n",
    "    val_subset = Subset(trainval_dataset, val_idx)\n",
    "\n",
    "    # Transforms uygulanÄ±r\n",
    "    train_subset.dataset.transform = train_transform\n",
    "    val_subset.dataset.transform = val_test_transform\n",
    "\n",
    "    # DataLoader'lar\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "   \n",
    "\n",
    "    # Model, optimizer, criterion yeniden tanÄ±mlanÄ±r\n",
    "    model = ViT(\n",
    "            image_size = 256,\n",
    "            patch_size = 16,\n",
    "            num_classes = len(class_names),\n",
    "            dim = 192,\n",
    "            depth = 9,\n",
    "            heads = 12,\n",
    "            mlp_dim = 384,\n",
    "            dropout = 0,\n",
    "            emb_dropout = 0\n",
    "            )\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                                                    optimizer,\n",
    "                                                    T_max=num_epochs,eta_min=0)\n",
    "    \n",
    "    \n",
    "     # Fold iÃ§in klasÃ¶r oluÅŸtur\n",
    "    fold_save_dir = os.path.join(run_dir, f'fold_{fold+1}')\n",
    "    os.makedirs(fold_save_dir, exist_ok=True)\n",
    "\n",
    "    train_model(model, criterion,  optimizer, scheduler,  train_loader, val_loader, val_loader, device,\n",
    "                num_epochs=num_epochs, save_policy=save_policy,\n",
    "                base_output_dir=fold_save_dir,class_names=class_names)\n",
    "\n",
    "     # Final test evaluation\n",
    "    test_loss, test_acc, test_prec, test_rec, test_f1, _, _ = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "    with open(os.path.join(fold_save_dir, 'test_metrics.txt'), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Loss', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "        writer.writerow([\n",
    "            round(test_loss, 4),\n",
    "            round(test_acc, 4),\n",
    "            round(test_prec, 4),\n",
    "            round(test_rec, 4),\n",
    "            round(test_f1, 4)\n",
    "        ])\n",
    "\n",
    "    all_fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'loss': test_loss,\n",
    "        'acc': test_acc,\n",
    "        'prec': test_prec,\n",
    "        'rec': test_rec,\n",
    "        'f1': test_f1\n",
    "    })\n",
    "\n",
    "# ==== Save average results as CSV-formatted text ====\n",
    "avg_metrics = {\n",
    "    'loss': np.mean([r['loss'] for r in all_fold_results]),\n",
    "    'acc': np.mean([r['acc'] for r in all_fold_results]),\n",
    "    'prec': np.mean([r['prec'] for r in all_fold_results]),\n",
    "    'rec': np.mean([r['rec'] for r in all_fold_results]),\n",
    "    'f1': np.mean([r['f1'] for r in all_fold_results])\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_dir, 'kfold_results.txt'), 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Fold', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "    for r in all_fold_results:\n",
    "        writer.writerow([\n",
    "            r['fold'],\n",
    "            round(r['loss'], 4),\n",
    "            round(r['acc'], 4),\n",
    "            round(r['prec'], 4),\n",
    "            round(r['rec'], 4),\n",
    "            round(r['f1'], 4)\n",
    "        ])\n",
    "    writer.writerow([])\n",
    "    writer.writerow(['Average', \n",
    "                     round(avg_metrics['loss'], 4),\n",
    "                     round(avg_metrics['acc'], 4),\n",
    "                     round(avg_metrics['prec'], 4),\n",
    "                     round(avg_metrics['rec'], 4),\n",
    "                     round(avg_metrics['f1'], 4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=\"./runs/run_2025-07-15_22-17-57/models\"\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, 'best_model.pt')))\n",
    "_, acc, prec, rec, f1, _, _ = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Best Model | Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf015b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
