{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff5ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a30be0e",
   "metadata": {},
   "source": [
    "https://github.com/lucidrains/vit-pytorch?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b853c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Custom Dataset ---\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            cls_path = os.path.join(root_dir, cls)\n",
    "            for img_name in os.listdir(cls_path):\n",
    "                self.image_paths.append(os.path.join(cls_path, img_name))\n",
    "                self.labels.append(self.class_to_idx[cls])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d281e1af-41a8-4473-b213-0d7f18b552ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout),\n",
    "                FeedForward(dim, mlp_dim, dropout = dropout)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94af16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses, preds, targets = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    prec, recall, f1, _ = precision_recall_fscore_support(targets, preds, average='macro', zero_division=0)\n",
    "    return np.mean(losses), acc, prec, recall, f1, preds, targets\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, test_loader, device, num_epochs, save_policy='min', save_dir='models'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    best_val_score = float('-inf')\n",
    "    worst_val_score = float('inf')\n",
    "    start_training_time = time.time()\n",
    "    now = datetime.now()\n",
    "    print(\"Starting time:\", now.strftime(\"%d-%m-%Y %H:%M:%S\"))\n",
    "    train_logs, val_logs = [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_losses, train_preds, train_targets = [], [], []\n",
    "       \n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            \n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        \n",
    "        train_loss = np.mean(train_losses)\n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_prec, train_rec, train_f1, _ = precision_recall_fscore_support(train_targets, train_preds, average='macro', zero_division=0)\n",
    "\n",
    "        val_loss, val_acc, val_prec, val_rec, val_f1, _, _ = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "        print(f\"Train | Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_prec:.4f} | Rec: {train_rec:.4f} | F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   | Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | Prec: {val_prec:.4f} | Rec: {val_rec:.4f} | F1: {val_f1:.4f}\")\n",
    "        print(f\"Epoch Time: {str(timedelta(seconds=epoch_time))} sec\\n\")\n",
    "\n",
    "        train_logs.append([epoch, train_loss, train_acc, train_prec, train_rec, train_f1, epoch_time])\n",
    "        val_logs.append([epoch, val_loss, val_acc, val_prec, val_rec, val_f1, epoch_time])\n",
    "\n",
    "        # Model saving policy\n",
    "        save_path = os.path.join(save_dir, f\"epoch_{epoch:03d}.pt\")\n",
    "        \n",
    "\n",
    "        if save_policy == 'max' and val_acc > best_val_score:\n",
    "            best_val_score = val_acc\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, 'best_model.pt'))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "\n",
    "        elif save_policy == 'last' :\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, 'best_model.pt'))\n",
    "\n",
    "    total_time = time.time() - start_training_time\n",
    "     \n",
    "    print(\"Fininsh time:\", datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\"))\n",
    "    print(f\"Total training time: {str(timedelta(seconds=total_time))} seconds\")\n",
    "\n",
    "    pd.DataFrame(train_logs, columns=['Epoch', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Time']).to_csv(os.path.join(save_dir, 'train_log.csv'), index=False)\n",
    "    pd.DataFrame(val_logs, columns=['Epoch', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Time']).to_csv(os.path.join(save_dir, 'val_log.csv'), index=False)\n",
    "\n",
    "    print(\"\\nðŸŽ¯ Final Evaluation on Test Set:\")\n",
    "    test_loss, test_acc, test_prec, test_rec, test_f1, test_preds, test_targets = evaluate_model(model, test_loader, criterion, device)\n",
    "    print(f\"Test | Loss: {test_loss:.4f} | Acc: {test_acc:.4f} | Prec: {test_prec:.4f} | Rec: {test_rec:.4f} | F1: {test_f1:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(test_targets, test_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(os.path.join(save_dir, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "  \n",
    "    model.load_state_dict(torch.load(os.path.join(save_dir, 'best_model.pt')))\n",
    "    _, acc, prec, rec, f1, _, _ = evaluate_model(model, test_loader, criterion, device)\n",
    "    print(f\"Best Model | Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21976291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef07d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Settings ---\n",
    "\n",
    "image_dir = 'DataSet/top-agriculture-crop-disease'          # Folder where images are stored\n",
    "image_size = 32\n",
    "batch_size = 32\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "num_workers = 4\n",
    "save_dir='vit_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "587a3a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 3 classes: ['Potato___Early_Blight', 'Potato___Healthy', 'Potato___Late_Blight']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Transforms ---\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# --- Load full dataset ---\n",
    "full_dataset = CustomDataset( image_dir)\n",
    "num_samples = len(full_dataset)\n",
    "num_val = int(num_samples * val_ratio)\n",
    "num_test = int(num_samples * test_ratio)\n",
    "num_train = num_samples - num_val - num_test\n",
    "\n",
    "# --- Split dataset ---\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [num_train, num_val, num_test])\n",
    "\n",
    "# Assign transforms after split\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_test_transform\n",
    "test_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "# --- DataLoaders ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# --- Class Info ---\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Loaded dataset with {num_classes} classes: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af08c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time: 14-07-2025 23:16:07\n",
      "Epoch [1/50]\n",
      "Train | Loss: 0.6319 | Acc: 0.7182 | Prec: 0.7186 | Rec: 0.7171 | F1: 0.7175\n",
      "Val   | Loss: 0.3635 | Acc: 0.8529 | Prec: 0.8712 | Rec: 0.8553 | F1: 0.8573\n",
      "Epoch Time: 0:00:07.985401 sec\n",
      "\n",
      "Epoch [2/50]\n",
      "Train | Loss: 0.3093 | Acc: 0.8768 | Prec: 0.8755 | Rec: 0.8757 | F1: 0.8754\n",
      "Val   | Loss: 0.2557 | Acc: 0.9020 | Prec: 0.9070 | Rec: 0.9038 | F1: 0.9034\n",
      "Epoch Time: 0:00:06.632752 sec\n",
      "\n",
      "Epoch [3/50]\n",
      "Train | Loss: 0.2146 | Acc: 0.9192 | Prec: 0.9186 | Rec: 0.9182 | F1: 0.9179\n",
      "Val   | Loss: 0.1445 | Acc: 0.9608 | Prec: 0.9597 | Rec: 0.9609 | F1: 0.9599\n",
      "Epoch Time: 0:00:07.343273 sec\n",
      "\n",
      "Epoch [4/50]\n",
      "Train | Loss: 0.1437 | Acc: 0.9478 | Prec: 0.9474 | Rec: 0.9471 | F1: 0.9471\n",
      "Val   | Loss: 0.2225 | Acc: 0.9118 | Prec: 0.9196 | Rec: 0.9151 | F1: 0.9140\n",
      "Epoch Time: 0:00:07.674053 sec\n",
      "\n",
      "Epoch [5/50]\n",
      "Train | Loss: 0.1053 | Acc: 0.9637 | Prec: 0.9634 | Rec: 0.9633 | F1: 0.9633\n",
      "Val   | Loss: 0.1687 | Acc: 0.9216 | Prec: 0.9266 | Rec: 0.9241 | F1: 0.9207\n",
      "Epoch Time: 0:00:08.231692 sec\n",
      "\n",
      "Epoch [6/50]\n",
      "Train | Loss: 0.0707 | Acc: 0.9739 | Prec: 0.9737 | Rec: 0.9734 | F1: 0.9735\n",
      "Val   | Loss: 0.2603 | Acc: 0.8954 | Prec: 0.9207 | Rec: 0.8982 | F1: 0.8998\n",
      "Epoch Time: 0:00:09.074631 sec\n",
      "\n",
      "Epoch [7/50]\n",
      "Train | Loss: 0.1090 | Acc: 0.9564 | Prec: 0.9560 | Rec: 0.9559 | F1: 0.9560\n",
      "Val   | Loss: 0.0992 | Acc: 0.9641 | Prec: 0.9637 | Rec: 0.9651 | F1: 0.9635\n",
      "Epoch Time: 0:00:20.851553 sec\n",
      "\n",
      "Epoch [8/50]\n",
      "Train | Loss: 0.0286 | Acc: 0.9902 | Prec: 0.9901 | Rec: 0.9900 | F1: 0.9901\n",
      "Val   | Loss: 0.0758 | Acc: 0.9804 | Prec: 0.9809 | Rec: 0.9790 | F1: 0.9798\n",
      "Epoch Time: 0:00:09.051788 sec\n",
      "\n",
      "Epoch [9/50]\n",
      "Train | Loss: 0.0372 | Acc: 0.9869 | Prec: 0.9868 | Rec: 0.9868 | F1: 0.9868\n",
      "Val   | Loss: 0.0921 | Acc: 0.9739 | Prec: 0.9726 | Rec: 0.9745 | F1: 0.9730\n",
      "Epoch Time: 0:00:08.695411 sec\n",
      "\n",
      "Epoch [10/50]\n",
      "Train | Loss: 0.0504 | Acc: 0.9845 | Prec: 0.9845 | Rec: 0.9844 | F1: 0.9845\n",
      "Val   | Loss: 0.1134 | Acc: 0.9673 | Prec: 0.9660 | Rec: 0.9683 | F1: 0.9666\n",
      "Epoch Time: 0:00:08.707891 sec\n",
      "\n",
      "Epoch [11/50]\n",
      "Train | Loss: 0.0229 | Acc: 0.9931 | Prec: 0.9932 | Rec: 0.9930 | F1: 0.9931\n",
      "Val   | Loss: 0.1799 | Acc: 0.9248 | Prec: 0.9263 | Rec: 0.9278 | F1: 0.9258\n",
      "Epoch Time: 0:00:08.270698 sec\n",
      "\n",
      "Epoch [12/50]\n",
      "Train | Loss: 0.0113 | Acc: 0.9976 | Prec: 0.9976 | Rec: 0.9975 | F1: 0.9976\n",
      "Val   | Loss: 0.1234 | Acc: 0.9706 | Prec: 0.9700 | Rec: 0.9715 | F1: 0.9706\n",
      "Epoch Time: 0:00:08.515956 sec\n",
      "\n",
      "Epoch [13/50]\n",
      "Train | Loss: 0.0048 | Acc: 0.9984 | Prec: 0.9984 | Rec: 0.9984 | F1: 0.9984\n",
      "Val   | Loss: 0.1534 | Acc: 0.9575 | Prec: 0.9612 | Rec: 0.9589 | F1: 0.9585\n",
      "Epoch Time: 0:00:08.723175 sec\n",
      "\n",
      "Epoch [14/50]\n",
      "Train | Loss: 0.0150 | Acc: 0.9947 | Prec: 0.9947 | Rec: 0.9947 | F1: 0.9947\n",
      "Val   | Loss: 0.1203 | Acc: 0.9641 | Prec: 0.9634 | Rec: 0.9654 | F1: 0.9642\n",
      "Epoch Time: 0:00:08.141978 sec\n",
      "\n",
      "Epoch [15/50]\n",
      "Train | Loss: 0.0761 | Acc: 0.9710 | Prec: 0.9708 | Rec: 0.9708 | F1: 0.9708\n",
      "Val   | Loss: 0.1243 | Acc: 0.9608 | Prec: 0.9593 | Rec: 0.9603 | F1: 0.9598\n",
      "Epoch Time: 0:00:08.367325 sec\n",
      "\n",
      "Epoch [16/50]\n",
      "Train | Loss: 0.0243 | Acc: 0.9918 | Prec: 0.9917 | Rec: 0.9917 | F1: 0.9917\n",
      "Val   | Loss: 0.1001 | Acc: 0.9706 | Prec: 0.9710 | Rec: 0.9684 | F1: 0.9695\n",
      "Epoch Time: 0:00:08.312160 sec\n",
      "\n",
      "Epoch [17/50]\n",
      "Train | Loss: 0.0021 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "Val   | Loss: 0.0844 | Acc: 0.9771 | Prec: 0.9764 | Rec: 0.9764 | F1: 0.9764\n",
      "Epoch Time: 0:00:08.668366 sec\n",
      "\n",
      "Epoch [18/50]\n",
      "Train | Loss: 0.0009 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "Val   | Loss: 0.0894 | Acc: 0.9804 | Prec: 0.9796 | Rec: 0.9801 | F1: 0.9798\n",
      "Epoch Time: 0:00:08.937856 sec\n",
      "\n",
      "Epoch [19/50]\n",
      "Train | Loss: 0.0007 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "Val   | Loss: 0.0905 | Acc: 0.9804 | Prec: 0.9796 | Rec: 0.9801 | F1: 0.9798\n",
      "Epoch Time: 0:00:08.804705 sec\n",
      "\n",
      "Epoch [20/50]\n",
      "Train | Loss: 0.0006 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "Val   | Loss: 0.0919 | Acc: 0.9804 | Prec: 0.9796 | Rec: 0.9801 | F1: 0.9798\n",
      "Epoch Time: 0:00:08.473049 sec\n",
      "\n",
      "Epoch [21/50]\n",
      "Train | Loss: 0.0005 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "Val   | Loss: 0.0939 | Acc: 0.9804 | Prec: 0.9796 | Rec: 0.9801 | F1: 0.9798\n",
      "Epoch Time: 0:00:08.068604 sec\n",
      "\n",
      "Epoch [22/50]\n",
      "Train | Loss: 0.0004 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "Val   | Loss: 0.0949 | Acc: 0.9804 | Prec: 0.9796 | Rec: 0.9801 | F1: 0.9798\n",
      "Epoch Time: 0:00:09.442053 sec\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvit_models\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_loader, val_loader, test_loader, device, num_epochs, save_policy, save_dir)\u001b[0m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     30\u001b[0m train_losses, train_preds, train_targets \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[0;32m---> 33\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1458\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1420\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1420\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1422\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(res)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:541\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 541\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    543\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/resource_sharer.py:86\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     85\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[0;32m---> 86\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m c\u001b[38;5;241m.\u001b[39msend((key, os\u001b[38;5;241m.\u001b[39mgetpid()))\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:526\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     answer_challenge(c, authkey)\n\u001b[0;32m--> 526\u001b[0m     \u001b[43mdeliver_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:757\u001b[0m, in \u001b[0;36mdeliver_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    755\u001b[0m connection\u001b[38;5;241m.\u001b[39msend_bytes(CHALLENGE \u001b[38;5;241m+\u001b[39m message)\n\u001b[1;32m    756\u001b[0m digest \u001b[38;5;241m=\u001b[39m hmac\u001b[38;5;241m.\u001b[39mnew(authkey, message, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmd5\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdigest()\n\u001b[0;32m--> 757\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;241m==\u001b[39m digest:\n\u001b[1;32m    759\u001b[0m     connection\u001b[38;5;241m.\u001b[39msend_bytes(WELCOME)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:437\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxsize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m size \u001b[38;5;241m>\u001b[39m maxsize:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = ViT(\n",
    "    image_size = 256,\n",
    "    patch_size = 16,\n",
    "    num_classes = len(class_names),\n",
    "    dim = 192,\n",
    "    depth = 9,\n",
    "    heads = 12,\n",
    "    mlp_dim = 384,\n",
    "    dropout = 0,\n",
    "    emb_dropout = 0\n",
    ")\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "train_model(model, criterion, optimizer, train_loader, val_loader, test_loader, device,\n",
    "            num_epochs=10, save_policy='last', save_dir='vit_models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8dc0cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model | Acc: 0.9790 | Prec: 0.9770 | Rec: 0.9790 | F1: 0.9779\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(save_dir, 'best_model.pt')))\n",
    "_, acc, prec, rec, f1, _, _ = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Best Model | Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
